{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19685 files belonging to 3 classes.\n",
      "Using 13780 files for training.\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "def AboutDataset():\n",
    "    path = 'Datasets\\COVID-19 CT Scan Images\\Original CT Scans'\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(path,\n",
    "                                                              labels='inferred',\n",
    "                                                              label_mode='int',\n",
    "                                                              color_mode='rgb',\n",
    "                                                              image_size=(300,300),\n",
    "                                                              batch_size=32,\n",
    "                                                              validation_split=0.3,\n",
    "                                                              subset='training',\n",
    "                                                              shuffle=True,\n",
    "                                                              seed=123         \n",
    "                                                           )\n",
    "    length = len(list(pathlib.Path(path).glob('*/*.jpg')))\n",
    "    \n",
    "    L1Text.set(\"Dataset Name : Chest X-Ray image Dataset (Source: Kaggle)\" +'\\n'+ \n",
    "               \" Total Files : \"+ str(str(length)) + '\\n' +\n",
    "               \"Total Classes : \"+ str(train_ds.class_names)+ '\\n'+\n",
    "               \"Number of Batches : \" + str(train_ds.cardinality().numpy()) +'\\n'+\n",
    "               \"Training Dataset : \" + str(math.floor(0.7*length)) +'\\n'+\n",
    "               \"Validation Dataset : \" + str(math.floor(0.3*length)))\n",
    "\n",
    "def SampleImages():\n",
    "    fp = open(\"C:\\\\Users\\\\Lenovo\\\\Datasets\\\\SampleImages\\\\all.png\",\"rb\")\n",
    "    img = PIL.Image.open(fp)\n",
    "    img = img.resize((800, 400))\n",
    "    photo = PIL.ImageTk.PhotoImage(img)\n",
    "    L11.configure(image=photo)\n",
    "    L11.image = photo\n",
    "    \n",
    "def NNInfo():\n",
    "    fp = open(\"C:\\\\Users\\\\Lenovo\\\\Datasets\\\\SampleImages\\\\model_plot.png\",\"rb\")\n",
    "    img = PIL.Image.open(fp)\n",
    "    img = img.resize((400, 700))\n",
    "    photo = PIL.ImageTk.PhotoImage(img)\n",
    "    L11.configure(image=photo)\n",
    "    L11.image = photo    \n",
    "\n",
    "def ModelSummary():\n",
    "    fp = open(\"C:\\\\Users\\\\Lenovo\\\\Datasets\\\\SampleImages\\\\summary.png\",\"rb\")\n",
    "    img = PIL.Image.open(fp)\n",
    "    #img = img.resize((350, 1000))\n",
    "    photo = PIL.ImageTk.PhotoImage(img)\n",
    "    L11.configure(image=photo)\n",
    "    L11.image = photo    \n",
    "    \n",
    "def SelectImage():\n",
    "    input = filedialog.askopenfile(initialdir=\"/\", filetypes=[('images','*.jpg')])\n",
    "    \n",
    "    fp = open(input.name,\"rb\")\n",
    "    img = PIL.Image.open(fp)\n",
    "    img = img.resize((300, 300))\n",
    "    photo = PIL.ImageTk.PhotoImage(img)\n",
    "    L11.configure(image=photo)\n",
    "    L11.image = photo    \n",
    "    \n",
    "    image = tf.keras.preprocessing.image.load_img(input.name,target_size=(300,300))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])\n",
    "    predictions = new_model.predict(input_arr)\n",
    "    l=['NiCT', 'nCT', 'pCT']\n",
    "    L2Text.set(\"Prediction Result = \"+ str(l[np.argmax(predictions)]) )\n",
    "    #print(np.argmax(predictions))\n",
    "   \n",
    "    \n",
    "new_model = tf.keras.models.load_model('C:\\\\Users\\\\Lenovo\\\\Saved_Models\\\\Final_Covid_Model1')\n",
    "#new_model.summary()    \n",
    "\n",
    "root = Tk()\n",
    "H1 = Label(root,text=\"Covid19 Detection in Chest X-Ray image using Deep Neural Network\", font=50, bg=\"yellow\",anchor = CENTER)\n",
    "H1.grid(row=0,column=6)\n",
    "H2 = Label(root,text=\"\").grid(row=1,column=0)\n",
    "\n",
    "MB1 = Button(root,text=\"About Dataset\",command = AboutDataset).grid(row=3,column=1)\n",
    "MB2 = Button(root,text=\"Sample Images\", command=SampleImages).grid(row=3,column=2)\n",
    "MB3 = Button(root,text=\"Get Layer info\", command=NNInfo).grid(row=3,column=3)\n",
    "MB3 = Button(root,text=\"Get Model Summary\", command=ModelSummary).grid(row=3,column=4)\n",
    "MB4 = Button(root,text=\"Predict X-Ray\", command=lambda:SelectImage()).grid(row=3,column=5)\n",
    "\n",
    "L1 = Label(root,text=\"\").grid(row=4,column=1,columnspan=2)\n",
    "\n",
    "L1Text = StringVar()\n",
    "L1 = Label(root, textvariable=L1Text)\n",
    "L1.grid(row=5,column=0,columnspan=4)\n",
    "\n",
    "L2Text = StringVar()\n",
    "L2 = Label(root, textvariable=L2Text)\n",
    "L2.grid(row=5,column=6)\n",
    "\n",
    "L11 = Label(root)\n",
    "L11.grid(row=6,column=6, rowspan=10)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
